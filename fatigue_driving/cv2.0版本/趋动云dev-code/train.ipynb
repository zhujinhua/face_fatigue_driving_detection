{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b007fca-de8d-41ca-806e-bf4227c191ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27cd2c-06a2-4d77-bcfe-2f3e6bf0c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /gemini/data-1/Fatigue.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f2761-8bf2-49de-982b-34b8290656be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/'\n",
    "# Ëé∑ÂèñÊâÄÊúâÂõæÂÉèÊñá‰ª∂ÂíåÊ†áÊ≥®Êñá‰ª∂Ë∑ØÂæÑ\n",
    "image_files = glob(os.path.join(dataset_path, 'images', '*.jpg'))\n",
    "annotation_files = glob(os.path.join(dataset_path, 'Annotations', '*.xml'))\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26a9f5-f069-447d-9de9-5ab8faee3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Â§ÑÁêÜÊ≤°ÊúâÊ†áÁ≠æÁöÑÂõæÁâáÔºåÂè™Ë¶ÅÁ¨¨‰∏ÄÊ¨°ËøêË°å\n",
    "# for pic in image_files:\n",
    "#     anno_name = (pic.split('.')[0] + '.xml').replace('images','Annotations')\n",
    "#     if anno_name not in annotation_files:\n",
    "#         os.remove(os.path.join(pic))\n",
    "\n",
    "# ÊâãÂä®Â∞ÜJPEGImagesÈáçÂëΩÂêç‰∏∫images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa3e64-2ade-40c0-a589-2910a1efe9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËΩ¨Êç¢VOCÊ†ºÂºèÊï∞ÊçÆ‰∏∫YOLOÊ†ºÂºè\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "classes = ['closed_eye', 'open_eye','closed_mouth','open_mouth']  # Ê†πÊçÆ‰Ω†ÁöÑÊï∞ÊçÆÈõÜÁ±ªÂà´‰øÆÊîπ\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    x = (box[0] + box[1]) / 2.0 - 1\n",
    "    y = (box[2] + box[3]) / 2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def convert_annotation(image_id):\n",
    "    in_file = open(dataset_path+'Annotations/%s.xml' % (image_id))\n",
    "    out_file = open(dataset_path+'labels/%s.txt' % (image_id), 'w')\n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult) == 1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text),\n",
    "             float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((w, h), b)\n",
    "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "if not os.path.exists(dataset_path+'labels/'):\n",
    "    os.makedirs(dataset_path+'labels/')\n",
    "for filename in annotation_files:\n",
    "    if filename.endswith('.xml'):\n",
    "        # file_path = os.path.join(path, filename)\n",
    "        image_id = os.path.splitext(os.path.basename(filename))[0]\n",
    "        convert_annotation(image_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb35d18-9f24-48b4-9080-7512ed98e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËøõË°å8:2ÂàÜÂâ≤\n",
    "\n",
    "labels_files = glob(os.path.join(dataset_path, 'labels', '*.txt'))\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    image_files, labels_files, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57740af-f0a1-4ac2-bb28-499c1ebcdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞ÜÊñá‰ª∂Ë∑ØÂæÑÂÜôÂÖ•ÊñáÊú¨Êñá‰ª∂\n",
    "dataset_path = 'datasets/'\n",
    "\n",
    "if not os.path.exists(dataset_path+'paths/'):\n",
    "    os.makedirs(dataset_path+'paths/')\n",
    "def write_file_list(file_list, filename):\n",
    "    filename = os.path.join(dataset_path,'paths', filename)\n",
    "    with open(filename, 'w') as f:\n",
    "        for file in file_list:\n",
    "            f.write(f\"{file}\\n\")\n",
    "\n",
    "write_file_list(train_images, 'train_images.txt')\n",
    "write_file_list(val_images, 'val_images.txt')\n",
    "write_file_list(train_labels, 'train_labels.txt')\n",
    "write_file_list(val_labels, 'val_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c950005a-bbc4-4c91-b9ce-bc1daac27d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÁîüÊàêmy_det_data.yamlÊñá‰ª∂\n",
    "data = {\n",
    "    'train': 'paths/train_images.txt',\n",
    "    'val': 'paths/val_images.txt',\n",
    "    'nc': 4,  \n",
    "    'names': ['closed_eye', 'open_eye','closed_mouth','open_mouth']\n",
    "}\n",
    "\n",
    "with open('Fatigue_det_data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067d4ca5-3370-4fc7-bd26-00445a75f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0195aee-83e1-4b0d-b383-6466f966b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.16 üöÄ Python-3.11.8 torch-2.1.2+cu121 CUDA:0 (B1.gpu.small, 5922MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=Fatigue_det_data.yaml, epochs=10, time=None, patience=100, batch=2, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=1, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks skipped ‚ö†Ô∏è, offline and unable to download YOLOv8n. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning dataset/labels... 2331 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:04<00:00, 541.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: dataset/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/albumentations/core/composition.py:151: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  warnings.warn(f\"Got processor for {proc.default_data_name}, but no transform to process it.\")\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning dataset/labels... 583 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:01<00:00, 480.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: dataset/labels.cache\n",
      "Plotting labels to runs/detect/train4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 320 train, 320 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/albumentations/core/composition.py:151: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  warnings.warn(f\"Got processor for {proc.default_data_name}, but no transform to process it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.564G      1.888      4.022     0.8571          5        320:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 772/1166 [00:52<00:20, 18.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.564G      2.089      4.026     0.9223          6        320:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 864/1166 [00:57<00:15, 19.81it/s]\n",
      "       1/10     0.564G      2.098      4.024     0.9246          6        320:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 869/1166 [00:57<00:15, 19.40it/s]\n",
      "       1/10     0.564G      2.114       4.02     0.9313          5        320:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 879/1166 [00:58<00:16, 17.50it/s]\n",
      "       1/10     0.564G      2.119      4.018     0.9331          5        320:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 885/1166 [00:58<00:15, 18.36it/s]\n",
      "       1/10     0.564G      2.129      4.019     0.9358          5        320:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 889/1166 [00:58<00:15, 17.61it/s]\n",
      "       1/10     0.564G      2.135      4.017     0.9378          6        320:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 893/1166 [00:58<00:14, 18.25it/s]\n",
      "       1/10     0.564G      2.145      4.014      0.941          5        320:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 898/1166 [00:59<00:14, 18.41it/s]\n",
      "       1/10     0.564G      2.162      4.014     0.9466          5        320:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 907/1166 [00:59<00:13, 18.75it/s]\n",
      "       1/10     0.564G      2.196      4.008     0.9552          6        320:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 929/1166 [01:00<00:12, 19.26it/s]\n",
      "       1/10     0.564G      2.289      3.975     0.9829          5        320:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 997/1166 [01:04<00:09, 18.69it/s]\n",
      "       1/10     0.564G      2.315      3.959     0.9894          5        320:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1020/1166 [01:05<00:07, 18.32it/s]\n",
      "       1/10     0.564G      2.332      3.951     0.9944          5        320:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1037/1166 [01:06<00:07, 18.17it/s]\n",
      "       1/10     0.564G      2.368      3.922      1.007          5        320:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1081/1166 [01:08<00:04, 17.85it/s]\n",
      "       1/10     0.564G      2.396      3.898      1.016          6        320:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1119/1166 [01:10<00:02, 18.83it/s]\n",
      "       1/10     0.564G      2.423      3.872      1.025          5        320:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1156/1166 [01:12<00:00, 17.95it/s]\n",
      "       1/10     0.564G      2.431      3.862      1.028          3        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:13<00:00, 15.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   9%|‚ñâ         | 13/146 [00:02<00:12, 10.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|‚ñà‚ñà‚ñà‚ñâ      | 58/146 [00:03<00:03, 25.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 127/146 [00:06<00:00, 27.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:06<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.546      0.242      0.216     0.0649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 328k/755k [00:24<00:54, 8.08kB/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 344k/755k [00:25<00:47, 8.81kB/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 360k/755k [00:27<00:41, 9.67kB/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 376k/755k [00:27<00:33, 11.6kB/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 392k/755k [00:28<00:26, 14.2kB/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 408k/755k [00:29<00:24, 14.3kB/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 424k/755k [00:31<00:25, 13.3kB/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 440k/755k [00:32<00:23, 13.8kB/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       2/10     0.533G      3.103      2.877      1.209          5        320:   1%|‚ñè         | 17/1166 [00:00<01:02, 18.49it/s]\n",
      "       2/10     0.533G      3.078      2.818      1.259          5        320:   3%|‚ñé         | 38/1166 [00:02<01:05, 17.19it/s]\n",
      "       2/10     0.533G      3.009      2.744      1.233          5        320:   8%|‚ñä         | 89/1166 [00:05<01:01, 17.40it/s]\n",
      "       2/10     0.533G      2.986       2.73      1.234          4        320:   9%|‚ñä         | 102/1166 [00:05<01:00, 17.61it/s]\n",
      "       2/10     0.533G       2.99      2.716      1.241          5        320:  12%|‚ñà‚ñè        | 135/1166 [00:07<00:56, 18.20it/s]\n",
      "       2/10     0.533G      2.974      2.678      1.237          6        320:  13%|‚ñà‚ñé        | 155/1166 [00:08<00:54, 18.68it/s]\n",
      "       2/10     0.533G      2.955      2.677      1.232          5        320:  16%|‚ñà‚ñå        | 184/1166 [00:10<00:51, 19.17it/s]\n",
      "       2/10     0.533G      2.953      2.666      1.239          5        320:  18%|‚ñà‚ñä        | 211/1166 [00:11<00:49, 19.29it/s]\n",
      "       2/10     0.533G      2.965      2.662      1.234          6        320:  20%|‚ñà‚ñâ        | 231/1166 [00:12<00:49, 18.98it/s]\n",
      "       2/10     0.533G      2.924      2.611      1.217          6        320:  25%|‚ñà‚ñà‚ñå       | 292/1166 [00:16<00:47, 18.49it/s]\n",
      "       2/10     0.533G       2.91      2.587      1.209          6        320:  27%|‚ñà‚ñà‚ñã       | 314/1166 [00:17<00:42, 19.86it/s]\n",
      "       2/10     0.533G       2.88      2.559      1.197          6        320:  32%|‚ñà‚ñà‚ñà‚ñè      | 373/1166 [00:20<00:44, 17.80it/s]\n",
      "       2/10     0.533G      2.855      2.533      1.194          5        320:  36%|‚ñà‚ñà‚ñà‚ñå      | 416/1166 [00:22<00:42, 17.84it/s]\n",
      "       2/10     0.533G      2.848       2.52      1.196          6        320:  38%|‚ñà‚ñà‚ñà‚ñä      | 438/1166 [00:24<00:41, 17.62it/s]\n",
      "       2/10     0.533G      2.845      2.515      1.195          6        320:  38%|‚ñà‚ñà‚ñà‚ñä      | 448/1166 [00:24<00:39, 18.10it/s]\n",
      "       2/10     0.533G      2.854       2.52      1.194          6        320:  40%|‚ñà‚ñà‚ñà‚ñâ      | 463/1166 [00:25<00:39, 17.75it/s]\n",
      "       2/10     0.533G      2.851      2.507      1.191          6        320:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 506/1166 [00:27<00:36, 17.87it/s]\n",
      "       2/10     0.533G      2.849      2.504      1.191          6        320:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 519/1166 [00:28<00:36, 17.89it/s]\n",
      "       2/10     0.533G      2.847      2.502       1.19          5        320:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 521/1166 [00:28<00:35, 18.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [01:02<00:00, 12.4kB/s]\u001b[A\n",
      "       2/10     0.533G      2.684      2.277      1.144          3        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:03<00:00, 18.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:05<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.607      0.695      0.652      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.535G      2.306      1.817      1.045          2        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:03<00:00, 18.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.589      0.747      0.739      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.533G      2.153      1.619      1.005          2        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:03<00:00, 18.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 29.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.695      0.787      0.786      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.533G      2.071       1.52     0.9806          2        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:03<00:00, 18.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 29.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.731      0.773      0.818      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.533G      2.012      1.433     0.9656          3        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:02<00:00, 18.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.736      0.799      0.871      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.533G      1.957      1.368     0.9583          2        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:02<00:00, 18.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.764      0.803      0.873      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.533G      1.908      1.324     0.9473          3        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:02<00:00, 18.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 34.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.828      0.819      0.897      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.533G      1.838      1.247      0.939          3        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:01<00:00, 18.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 36.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.829      0.825      0.906      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.533G      1.836      1.213     0.9315          3        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1166/1166 [01:13<00:00, 15.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:04<00:00, 31.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.819       0.85      0.918      0.446\n",
      "\n",
      "10 epochs completed in 0.207 hours.\n",
      "Optimizer stripped from runs/detect/train4/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train4/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train4/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.16 üöÄ Python-3.11.8 torch-2.1.2+cu121 CUDA:0 (B1.gpu.small, 5922MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:03<00:00, 38.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.819       0.85      0.918      0.445\n",
      "            closed_eye        583        409      0.896       0.72       0.88      0.388\n",
      "              open_eye        583        595      0.815      0.801      0.875      0.391\n",
      "          closed_mouth        583        516      0.925      0.975      0.985      0.529\n",
      "            open_mouth        583         52      0.641      0.904      0.932      0.473\n",
      "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "results = model.train(data=\"Fatigue_det_data.yaml\", \n",
    "                      epochs=10, \n",
    "                      imgsz=320, \n",
    "                      batch=2,\n",
    "                      workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8b5128d-2267-4ff6-92e1-59f1586645b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.16 üöÄ Python-3.11.8 torch-2.1.2+cu121 CUDA:0 (B1.gpu.small, 5922MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=Fatigue_det_data.yaml, epochs=20, time=None, patience=100, batch=4, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=1, project=None, name=train42, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.5, mixup=0.2, copy_paste=0.2, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train42\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train42', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks skipped ‚ö†Ô∏è, offline and unable to download YOLOv8n. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning dataset/labels... 2331 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:03<00:00, 584.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: dataset/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/albumentations/core/composition.py:151: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  warnings.warn(f\"Got processor for {proc.default_data_name}, but no transform to process it.\")\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning dataset/labels... 583 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:00<00:00, 714.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: dataset/labels.cache\n",
      "Plotting labels to runs/detect/train42/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 320 train, 320 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20     0.591G      2.642      5.676      1.189          8        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:47<00:00, 12.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.455      0.223      0.166     0.0467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20     0.562G      2.879      2.453      1.182         13        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:42<00:00, 13.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 20.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.436      0.625        0.5      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20     0.562G      2.496      1.933      1.068          8        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:46<00:00, 12.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.604      0.687      0.705       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20     0.562G      2.393      1.775      1.046         12        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:46<00:00, 12.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:05<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.697      0.753      0.764      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      0.56G      2.267      1.658      1.015         10        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:47<00:00, 12.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.724      0.742      0.789      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20     0.562G      2.174       1.54      0.987          9        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:46<00:00, 12.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.732      0.794      0.828      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      0.56G      2.126      1.454     0.9846         10        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:45<00:00, 12.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 18.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.791      0.804      0.873      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20     0.558G      2.081      1.401     0.9757          7        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:53<00:00, 10.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572       0.84       0.83      0.906      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20     0.562G      2.051      1.304     0.9662          8        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:50<00:00, 11.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.871      0.835      0.933      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      0.56G      1.977      1.263     0.9561         17        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:49<00:00, 11.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572       0.86      0.864      0.938      0.468\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/albumentations/core/composition.py:151: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  warnings.warn(f\"Got processor for {proc.default_data_name}, but no transform to process it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20     0.556G      1.809      1.108     0.9293          7        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:45<00:00, 12.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.903       0.88      0.941      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20     0.556G      1.777      1.054     0.9255          9        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:44<00:00, 12.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.909      0.854      0.957      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20     0.556G      1.729      1.005      0.922          9        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:43<00:00, 13.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:05<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.931      0.882      0.961      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20     0.556G      1.732      0.987     0.9129          8        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:44<00:00, 13.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.902      0.918      0.961      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20     0.556G      1.695     0.9498      0.908          9        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:41<00:00, 13.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.887      0.925      0.962      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20     0.556G      1.668     0.9251     0.9075          8        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:39<00:00, 14.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:04<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.896      0.921      0.965      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20     0.556G       1.65     0.9094     0.9048          9        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:37<00:00, 15.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 20.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.912      0.907      0.967      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20     0.556G      1.633      0.887     0.8966          9        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:36<00:00, 15.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572       0.91       0.92      0.969      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20     0.554G      1.628     0.8693     0.8933          8        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:41<00:00, 14.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.926      0.933      0.975      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20     0.556G      1.605     0.8591     0.8954          6        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 583/583 [00:41<00:00, 14.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.916      0.941      0.973      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.280 hours.\n",
      "Optimizer stripped from runs/detect/train42/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train42/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train42/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.16 üöÄ Python-3.11.8 torch-2.1.2+cu121 CUDA:0 (B1.gpu.small, 5922MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:03<00:00, 22.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        583       1572      0.926      0.933      0.975      0.535\n",
      "            closed_eye        583        409      0.909        0.9      0.962      0.486\n",
      "              open_eye        583        595      0.933       0.86      0.958      0.456\n",
      "          closed_mouth        583        516      0.964      0.992      0.994      0.562\n",
      "            open_mouth        583         52      0.897      0.981      0.986      0.636\n",
      "Speed: 0.0ms preprocess, 1.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train42\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ‰ºòÂåñÂèÇÊï∞ÊñπÊ°à‰∏ÄÔºöÂ¢ûÂä†Êï∞ÊçÆÂ¢ûÂº∫„ÄÅËΩÆÊï∞„ÄÅbatch\n",
    "results = model.train(data=\"Fatigue_det_data.yaml\", \n",
    "                      epochs=20, \n",
    "                      imgsz=320, \n",
    "                      batch=4,\n",
    "                      workers=1,\n",
    "                      mosaic=0.5,  # Â¢ûÂä†mosaicÊï∞ÊçÆÂ¢ûÂº∫\n",
    "                      mixup=0.2,   # Â¢ûÂä†mixupÊï∞ÊçÆÂ¢ûÂº∫\n",
    "                      copy_paste=0.2)  # Â¢ûÂä†copy-pasteÊï∞ÊçÆÂ¢ûÂº∫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4af186c-6ea0-43fc-8317-6932ccfd5bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: gemini/code/runs/detect/train42/ (stored 0%)\n",
      "  adding: gemini/code/runs/detect/train42/F1_curve.png (deflated 8%)\n",
      "  adding: gemini/code/runs/detect/train42/PR_curve.png (deflated 16%)\n",
      "  adding: gemini/code/runs/detect/train42/P_curve.png (deflated 12%)\n",
      "  adding: gemini/code/runs/detect/train42/R_curve.png (deflated 9%)\n",
      "  adding: gemini/code/runs/detect/train42/args.yaml (deflated 53%)\n",
      "  adding: gemini/code/runs/detect/train42/confusion_matrix.png (deflated 28%)\n",
      "  adding: gemini/code/runs/detect/train42/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: gemini/code/runs/detect/train42/events.out.tfevents.1721707730.gjob-dev-470774588713136128-taskrole1-0.1387.1 (deflated 92%)\n",
      "  adding: gemini/code/runs/detect/train42/labels.jpg (deflated 32%)\n",
      "  adding: gemini/code/runs/detect/train42/labels_correlogram.jpg (deflated 33%)\n",
      "  adding: gemini/code/runs/detect/train42/results.csv (deflated 83%)\n",
      "  adding: gemini/code/runs/detect/train42/results.png (deflated 8%)\n",
      "  adding: gemini/code/runs/detect/train42/train_batch0.jpg (deflated 6%)\n",
      "  adding: gemini/code/runs/detect/train42/train_batch1.jpg (deflated 5%)\n",
      "  adding: gemini/code/runs/detect/train42/train_batch2.jpg (deflated 6%)\n",
      "  adding: gemini/code/runs/detect/train42/train_batch5830.jpg (deflated 10%)\n",
      "  adding: gemini/code/runs/detect/train42/train_batch5831.jpg (deflated 5%)\n",
      "  adding: gemini/code/runs/detect/train42/train_batch5832.jpg (deflated 8%)\n",
      "  adding: gemini/code/runs/detect/train42/val_batch0_labels.jpg (deflated 11%)\n",
      "  adding: gemini/code/runs/detect/train42/val_batch0_pred.jpg (deflated 11%)\n",
      "  adding: gemini/code/runs/detect/train42/val_batch1_labels.jpg (deflated 11%)\n",
      "  adding: gemini/code/runs/detect/train42/val_batch1_pred.jpg (deflated 11%)\n",
      "  adding: gemini/code/runs/detect/train42/val_batch2_labels.jpg (deflated 11%)\n",
      "  adding: gemini/code/runs/detect/train42/val_batch2_pred.jpg (deflated 11%)\n",
      "  adding: gemini/code/runs/detect/train42/weights/ (stored 0%)\n",
      "  adding: gemini/code/runs/detect/train42/weights/best.pt (deflated 11%)\n",
      "  adding: gemini/code/runs/detect/train42/weights/last.pt (deflated 11%)\n"
     ]
    }
   ],
   "source": [
    "! zip -r /gemini/code/runs/detect/train42.zip /gemini/code/runs/detect/train42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d63665-3484-4ffe-9db3-0ca9d024f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "! zip -r /gemini/code/runs/detect/train42.zip /gemini/code/runs/detect/train42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
